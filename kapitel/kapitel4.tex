% kapitel4.tex
\definecolor{light-gray}{gray}{0.93}
\chapter{Laufzeitanalyse} \label{sec:}

\section{Laufzeit für die Graphkonstruktion und Bestimmung der Zusammenhangskomponenten} \label{sec:}
\subsubsection{Laufzeit für das Hinzufügen der Knoten des Graphen} \label{subsec:}
Die Laufzeit für das Hinzufügen eines Knotens (siehe Kap. \ref{subsec:nodes}) beträgt nach der Dokumentation von graph-tool  $ O(1) $ \cite{docs_graph_tool}. Die Zuweisung der Knoteneigenschaften erfolgt ebenfalls in $ O(1) $. Über alle Reads, also über die resultierende Anzahl der Knoten $ |V| $ ergibt sich daraus eine Gesamtlaufzeit von $ O(|V|) $.\\

\subsubsection{Laufzeit für das Hinzufügen der Kanten des Graphen} \label{subsec:}

Das Hinzufügen einer Kante im Graphen (siehe Kap. \ref{subsec:edges}) benötigt laut graph-tool Dokumentation \cite{docs_graph_tool} eine Laufzeit von $ O(1) $. Da aber die Query- und die Referenzreads aus dem Alignment den zuvor angelegten Knoten zugeordnet werden müssen, erfordert dies eine Suche der betreffenden Knoten im Graphen. Dabei durchsucht graph-tool mit seiner Funktion \lstinline|find_vertex()| allein die Knoten und prüft auf die gesuchte Read-ID aus dem FASTQ-File. Die ein- und ausgehenden Kanten der Knoten werden nicht beachtet, so dass eine Tiefen- oder Breitensuche des Graphen nicht notwendig ist und die Suche in $ O(|V|) $ durchgeführt werden kann ~\cite{graph_tool_coplexity_find_vertex}. Die Zuweisung der Kanteneigenschaften erfolgt jeweils in $ O(1) $, da diese direkt bei der Erzeugung der Kante hinzugefügt werden und keine vorherige Suche der Kante erforderlich ist. Für alle Kanten ergibt sich daraus eine Gesamtlaufzeit von $ O(|E|\, \cdotp |V|) $. \\


\subsubsection{Laufzeit zur Bestimmung der Zusammenhangskomponenten} \label{subsec:}

Die Bestimmung der Zusammenhangskomponenten $C = (C_{1}, \dots , C_{h})$ durch graph-tool kann in $ O(|V| + |E|) $ durchgeführt werden \cite{docs_graph_tool}, hierbei wird jedem Konten die Indexnummer seiner Zusammenhangskomponente zugewiesen (siehe Kap. \ref{subsec:comp}). Aus Zusammenhangskomponenten mit mehr als einem Knoten sollen hiernach eigenständige Subgraphen erzeugt werden. Dazu wird in der Funktion \lstinline|get_components()| des Moduls \lstinline|graph_operations.py| zunächst eine nach den Knoten der Komponente gefilterte View des Gesamtgraphen erzeugt, welche anschließend als neuer eigenständiger Graph initialisiert wird. Da beim Filtervorgang jeder Zusammenhangskomponente jeweils alle Knoten des Graphen betrachtet werden müssen, beträgt die Laufzeit hierfür $ O(h \, \cdotp |V|) $, wobei $h$ die Anzahl der Zusammenhangskomponenten ist. \\

Die Subgraphen der Zusammenhangskomponenten werden als Elemente einer Liste zusammengefasst. Durch Erstellen einer Liste von Subgraphen kann später eine einfache Iteration über die Komponenten in $ O(h) $ ausgeführt werden, ohne dass der Filtervorgang über alle Knoten jeder Komponente wiederholt werden muss. \\

Die Gesamtlaufzeit für die Bestimmung der Zusammenhangskomponenten und die Generierung eigenständiger Subgraphen beträgt nach Formel \eqref{eqn:4-1} somit $ O(h \, \cdotp |V| + |E|) $. 
\begin{equation} \label{eqn:4-1}
\tag{4-1}
\begin{aligned}
 O(h \, \cdotp |V|) \, + \, O(|V| + |E|) &\ {} = O(|V| \, \cdotp (h + 1) +|E|)\\
 &\ = O(h \, \cdotp |V| + |E|)
 \end{aligned}
\end{equation}

Bei realen Daten gibt es in der Regel deutlich mehr Knoten als Cluster bzw. Zusammenhangskomponenten, so dass gilt $ h < |V| $. Würde im Worst Case aber jede Zusammenhangskomponente aus nur einem Knoten bestehen, also $ h = |V| $, so kann die maximale Laufzeit auf $ O(|V|^2 + |E|) $ geschätzt werden (siehe Formel \eqref{eqn:4-2}).\\
\begin{equation} \label{eqn:4-2}
\tag{4-2}
\begin{aligned}
O(h \, \cdotp |V| + |E|) &\ {} = O(|V| \, \cdotp |V| + |E|)\\
&\ = O(|V|^2 + |E|) 
\end{aligned}
\end{equation}

\subsubsection{Gesamtlaufzeit der Konstruktion des Graphen und der Zusammenhangskomponenten} \label{subsec:graph_compl}
Aus den Laufzeiten für die Erzeugung der Knoten in $ O(|V|) $, das Hinzufügen der Kanten in $ O(|E|\, \cdotp |V|) $  sowie die Bestimmung und Extraktion der Zusammenhangskomponenten in $ O(|V|^2 + |E|) $ ergibt sich nach \eqref{eqn:4-3} eine Gesamtlaufzeit von $ O(|V| \, \cdotp (|V| + |E|)) $. \\
\begin{equation} \label{eqn:4-3}
\tag{4-3}
\begin{aligned}
&\ {} O(|V|) + O(|E|\, \cdotp |V|) + O(|V|^2 + |E|) \\
&\ = O(|V| + |V|\, \cdotp |E| + |V|^2 + |E|)\\
&\ = O(|V|\, \cdotp (1 + |E|) + |V|^2 + |E|)\\
&\ \in O(|V|\, \cdotp |E| + |V|^2 + |E|)\\
&\ = O(|V|^2 + |E| \, \cdotp (1 + |V|))\\
&\ \in O(|V|^2 + |E| \, \cdotp |V|)\\
&\ = O(|V| \, \cdotp (|V| + |E|))\\
\end{aligned}
\end{equation}

\section[Laufzeitberechnung der VAFs mit maximaler Likelihood]{Laufzeit zur Bestimmung der Allele-Fractions mit maximaler Likelihood}

Da alle weiteren Schritte für jede Zusammenhangskomponente $C_{i} \in \{C_{1}, \dots , C_{h}\}$ durchgeführt werden, sollen hier zunächst die Laufzeiten für eine Komponente betrachten werden und erst am Ende des Kapitels die Laufzeit für alle Komponenten bestimmt werden. Die Zusammenhangskomponenten sind Subgraphen des Gesamtgraphen $G=(V, \, E)$, so dass gilt $ C_{i} \subseteq G$ und $C_{i}=(V_{C_{i}}, \, E_{C_{i}})$. Sei also im Folgenden $|V_{C_{i}}|$ die Anzahl der Knoten innerhalb einer Komponente. \\ 

\subsubsection{Laufzeit der Funktion \lstinline|get_candidate_alleles()|}
Für das Erstellen der Liste von Kandidatenallelen muss jeder Knoten einer Zusammenhangskomponente betrachtet werden, so dass der Vorgang in $ O(|V_{C_{i}}|) $ durchführbar ist.\\

\subsubsection{Laufzeit der Funktion \lstinline|get_max_parsimony_n_alleles()|}
Die Anpassung der Anzahl der Allele an die gegebene Ploidie kann für jede Komponente in $ O(1) $ erfolgen.\\

\subsubsection{Laufzeit der Funktion \lstinline|get_candidate_vafs()|} \label{subsubsec:cand_vafs}
%\subsubsection{Abschätzung der oberenen Laufzeitschranke bei Kombinationen mit %Wiederholung und Laufzeit der Funktion \lstinline|get_candidate_vafs()|} 
Für die Bestimmung der Allelkombinationen werden durch Verwendung von \linebreak \lstinline|itertools.combinations_with_replacement()| alle Kombinationen der Kandidatenallele generiert, wobei Wiederholungen erlaubt sind. Da kombinatorische Problemstellungen zu hohen Laufzeiten und deutlichem Speicherplatzbedarf führen, sind sie oft der dominierende und ggf. auch limitierende Schritt eines Programms. Daher soll an dieser Stelle eine genauere Laufzeitabschätzung erfolgen. \\

Seien $k$ die Anzahl der Kandidatenallele und $n$ die Anzahl der Allele, die bei gegebener Ploidie nach \lstinline|get_max_parsimony_n_alleles()| zu erwarten sind, und es gilt $n, k \in \mathds{N} $.  Wie bereits in Kap. \ref{subsec:cand_allele} beschrieben, lässt sich die Anzahl aller Kombinationen mit Zurücklegen aus dem Binomialkoeffizienten nach  Formel \eqref{eqn:3-1} errechnen \cite{tb_stat}. Das bedeutet, dass für jede Zusammenhangskomponente $ \binom{n + k - 1}{k} $ Kombinationen jeweils in O(1) gebildet werden müssen. Die Laufzeit zum Erzeugen aller Kombinationen mit Zurücklegen entspricht somit genau ihrer Anzahl, so dass je Zusammenhangskomponente eine Laufzeit von $ O(\binom{n + k - 1}{k}) $ benötigt wird. Ebenso wird jede spätere Iteration über der Menge der aus den Allelkombinationen gebildeten Allel-Fractions die Laufzeit um den Faktor $ O(\binom{n + k - 1}{k}) $ erhöhen. Daher soll diese Laufzeit hinsichtlich ihrer oberen Schranken im Folgenden genauer abgeschätzt werden. \\

Die allgemeinene Formel des Binomialkoeffizienten \eqref{eqn:4-4} beschreibt die Anzahl aller Kombinationen ohne Zurücklegen. 
\begin{equation} \label{eqn:4-4}
\tag{4-4}
\binom{n}{k} = \frac{n!}{(n-k)!\, \cdotp k!}
\end{equation} 
Aus ihr kann die hier benötigte Anzahl aller Kombinationen mit Zurücklegen, also  $ \binom{n + k - 1}{k} $, abgeleitet werden, wenn gilt $ m = n + k - 1 $:
\begin{equation} \label{eqn:4-5}
\tag{4-5}
\begin{aligned}
\binom{m}{k} &\ {} = \frac{m!}{(m - k)!\, \cdotp k!} 
= \frac{(n+k-1)!}{((n+k-1)-k)!\, \cdotp k!} \\
&\ = \frac{(n+k-1)!}{(n-1)!\, \cdotp k!} 
= \binom{n + k - 1}{k}
\end{aligned}
\end{equation}

Mit anderen Worten, Kombinationen mit Zurücklegen können auf zwei Arten interpretiert werden: es werden aus n Elementen $ k $ Elemente mit Zurücklegen gezogen oder es werden aus $ n + k - 1 $ Elementen $ k $ Elemente ohne Zurücklegen gezogen. \\

Sei also für eine erste Laufzeitabschätzung $ m = n + k - 1 $, dann gilt:
\begin{equation} \label{eqn:4-6}
\tag{4-6}
\binom{m}{k} = \frac{m!}{(m - k)!\, \cdotp k!} \leq m!
\end{equation} 

Daraus ergibt sich nach \eqref{eqn:4-7} eine Laufzeit eine obere Schranke der Laufzeit von \linebreak $ O((n + k)!) $. 
\begin{equation} \label{eqn:4-7}
\tag{4-7}
O(m!) = O((n + k + 1)!) = O((n + k)!)
\end{equation} 

Hierfür soll nun eine kleinere obere Schranke gefunden werden. Allgemein lässt sich die Fakultät näherungsweise durch die Stirlingsche Formel \cite{bronst} abschätzen:
\begin{equation} \label{eqn:4-8}
\tag{4-8}
n! \approx \left( \frac{n}{e} \right) ^n \, \cdotp \sqrt{2 \, \cdotp \pi \, \cdotp n}
\end{equation} 

Daraus folgt, dass \eqref{eqn:4-9} eine untere Schranke der Fakultät ist \cite{script_binom}.
\begin{equation} \label{eqn:4-9}
\tag{4-9}
n! \geq \left( \frac{n}{e} \right) ^n 
\end{equation} 

Durch die Formeln \eqref{eqn:3-1} und \eqref{eqn:4-9} lässt sich durch einige Umformungen die obere Schranke der Laufzeit von ursprünglich $ O(n!) $  auf $ O\left( \left( \frac{e \, \cdotp (n + k - 1)}{k}\right)^k\right) $ eingrenzen:
\begin{equation} \label{eqn:4-10}
\tag{4-10}
\begin{aligned}
\binom{n + k - 1}{k} &\ {} \overset{\eqref{eqn:3-1}}{=}  \frac{(n+k-1)!}{(n-1)!\, \cdotp k!} = \frac{\prod\limits_{i=1}^{n+k-1}i}{\prod\limits_{i=1}^{n-1}i \; \cdotp \, \prod\limits_{i=1}^{k}i}  \\
&\ = \frac{\prod\limits_{i=n}^{n+k-1}i \; \cdotp \, \prod\limits_{i=1}^{n-1}i}{\prod\limits_{i=1}^{n-1}i \; \cdotp \, \prod\limits_{i=1}^{k}i} = \frac{\prod\limits_{i=n}^{n+k-1}i}{\prod\limits_{i=1}^{k}i}\\
&\ = \frac{(n + k - 1) \, \cdotp (n + k - 2)\, \cdotp \; \dots \; \, \cdotp n}{k!} \\
&\ \leq \frac{(n + k - 1)^k}{k!} \\
&\ \overset{\eqref{eqn:4-9}}{\leq} \frac{(n + k - 1)^k}{\left( \frac{k}{e} \right) ^k} \\
&\ = \left( \frac{e \, \cdotp (n + k - 1)}{k}\right)^k  \\
\end{aligned}
\end{equation} 

Diese obere Laufzeitschranke kann nun verwendet werden, um die Laufzeit im Worst Case zu bestimmen. Dazu soll zunächst der Worst Case selbst ermittelt werden. Da die Laufzeit der Anzahl der Kombinationen und damit dem Binomialkoefizienten entspricht, muss also ein möglichst großer Binomialkoeffizient gefunden werden, d.h. der Zusammenhang von $n$ und $k$ zueinander, so dass $\binom{n}{k}$ maximal wird.\\

Der Binomialkoeffizient verfügt über bestimmte Eigenschaften, insbesondere gelten der Symmetrie- \eqref{eqn:4-11} und der Additionssatz \eqref{eqn:4-12}, die sich auch in der Struktur des Pascalschen Dreiecks widerspiegeln \cite{bronst}. 
\begin{equation} \label{eqn:4-11}
\tag{4-11}
\binom{n}{k} = \binom{n}{n - k}
\end{equation} 
\begin{equation} \label{eqn:4-12}
\tag{4-12}
\binom{n}{k} + \binom{n}{k + 1} = \binom{n + 1}{k + 1} 
\end{equation} 
Aufgrund der Symmetrie sind die Binomialkoeffizienten jeder Zeile des Dreiecks $\binom{n}{k_{i}}$ mit $ k_{i} \in 1, \dots n $ und $ i \in \mathds{N} $ symmetrisch im Bezug auf die Zeilenmitte. Und da nach \eqref{eqn:4-12} jeder Koeffizient aus der Summe der beiden darüber liegenden Koeffizienten entsteht, sind die Werte der Koeffizienten zu den Zeilenrändern hin abnehmend und weisen in der Zeilenmitte ihr Maximum auf. Ist $n$ gerade, so befindet sich die Zeilenmitte bei $ k = \frac{n}{2} $. Ist $n$ ungerade so befinden sich die Maxima bei $ k = \lceil \frac{n}{2} \rceil $ und $ k = \lfloor \frac{n}{2} \rfloor $ und besitzen aufgrund der Symmetrie den gleichen Wert. Vereinfacht gilt also für ein gegebenes $n$, dass der Binomialkoeffizient $\binom{n}{k}$ bei $ k = \frac{n}{2} $ maximal ist. \\

Daher soll $ k = \frac{n}{2} $ als Worst Case angenommen werden, dann ergibt sich aus \eqref{eqn:4-10} eine Laufzeit von $ O(3e^{\frac{n}{2}} ) \in O(e^n) $. 
\begin{equation} \label{eqn:4-13}
\tag{4-13}
\begin{aligned}
\left( \frac{e \, \cdotp (n + k - 1)}{k}\right)^k &\ {} = \left( \frac{e \, \cdotp (n + \frac{n}{2} - 1)}{\frac{n}{2}}\right)^{\frac{n}{2}}  \\
&\ = \left( \frac{\frac{3en - 2e}{2}} {\frac{n}{2}}\right)^{\frac{n}{2}} \\
&\ = \left( \frac{3en - 2e}{n}\right)^{\frac{n}{2}} \\
&\ \leq \left( \frac{3en}{n}\right)^{\frac{n}{2}}\\
&\ = 3e^{\frac{n}{2}} \\
&\ \in O(e^n)\\
\end{aligned}
\end{equation}
Hinsichtlich der Allelkombinationen entspricht dies einer Zeit von $ O(e^n) $ für jede Zusammenhangskomponente.  \\

Für sehr große Cluster und Cluster mit vielen Varianten ist daher die Laufzeit problematisch. Ebenso kommt es zu einem hohen Bedarf an Arbeitsspeicher, aufgrund der großen Anzahl von Kombinationen die dabei erzeugt werden. Um dies bedingt kompensieren zu können, wurden die bereits beschriebenen Schwellenwerte eingeführt, die ober- und unterhalb einer festgelegten Clustergröße nur Kandidatenallele ab einer bestimmten Häufigkeit ihrer Sequenz in den Reads berücksichtigen (vgl. Kap. \ref{subsec:cand_allele}).\\

Bei der Berechnung der Allele-Fractions wird für jede Allelkombination die Häufigkeit der Kandidatenallele im Bezug auf die Allelkombination ermittelt. Es werden also alle $n$ Positionen jeder Kombination betrachtet, so dass die Laufzeit der Funktion \lstinline|get_candidate_vafs()| insgesamt $ O(n\, \cdotp e^n)$ beträgt. 

\subsubsection{Laufzeit der Funktion \lstinline|get_alignment_likelihood()|}

Für die Berechnung der Likelihood eines Read-Kandidatenallel-Paares wird die geschätzte Fehlerrate $ p_{query} $ jeder Base des Reads verwendet. Durch die Verwendung der CIGAR-Tupel werden die Likelihoodberechnungen meist gebündelt für mehrere Basen mit gleicher Operation (Match, Substitution, Insertion, Deletion) durchgeführt. Dennoch müssen vorab für alle Basen des Reads die Werte von $ p_{query} $ aus den Phred Quality Scores nach \eqref{eqn:3-3} ermittelt werden. Daher entspricht die Laufzeit für die Likelihoodberechnung eines Reads seiner Readlänge $ l = |s_{r}| $, also $O(l)$.


\subsubsection{Laufzeiten der Funktionen \lstinline|calc_vafs_likelihood()|, \lstinline|calc_vafs_likelihood()| und \lstinline|get_allele_likelihood_read()|}

Durch die Funktion \lstinline|calc_vafs_likelihood()| wird über alle Reads in $ O(|V_{C_{i}}|) $ und durch \lstinline|calc_vafs_likelihood_read()| über alle Kandidatenallele iteriert. Da die Anzahl der Kandidatenallele maximal so groß sein kann wie die tatsächliche Anzahl der Allele nach Berücksichtigung der Ploidie gilt $n \geq k$, kann für \lstinline|calc_vafs_likelihood_read()| die obere Laufzeitschranke mit $ O(n) $ veranschlagt werden. Die aus den beiden Funktionen generierten paarweisen Kombinationen der Kandidatenallele mit allen Reads werden an \linebreak \lstinline|get_allele_likelihood_read()| weitergereicht.\\

Dort wird zunächst das angelegte Dictionary nach bereits vorhandenen Einträgen durchsucht. Da hier maximal ein Eintrag für jedes Kandidatenallel zu jedem Read vorliegen kann, benötigt die Suche $ O(n \,\cdotp |V_{C_{i}}|) $ \cite{python-sort}. \\

Liegt kein Eintrag vor, so werden zunächst die ausgehenden Nachbarn durchsucht, und bei erfolgloser Suche, werden im Anschluss die eingehenden Nachbarn betrachtet. Die Anzahl der maximalen Suchvorgänge entspricht also der Summe der aus- und eingehenden Kanten des Reads. Somit entspricht die Laufzeit hierfür seinem Knotengrad $d$. Im Worst Case wäre die Zusammenhangskomponente ein vollständiger gerichteter Graph, so dass $ d = |V_{C_{i}}| - 1 $. Somit beträgt die Laufzeit für die Suchvorgänge maximal $O(|V_{C_{i}}|)$.\\

Die Suchvorgänge aus \lstinline|get_allele_likelihood_read()| werden genau so oft ausgeführt, bis alle Einträge im Dictionary erzeugt wurden, also $n \,\cdotp |V_{C_{i}}|$ Mal. Für jeden Eintrag ins Dictionary wird dann die Likelihood in $ O(l) $ errechnet. Daraus ergibt sich schließlich eine Laufzeit für die Suchvorgänge und die Likelihoodberechnungen von $ O(n \,\cdotp l \,\cdotp |V_{C_{i}}|^2)$ (siehe Formel \eqref{eqn:4-14}). Hiernach wird nur noch das Dictionary in $ O(n \,\cdotp |V_{C_{i}}|) $ durchsucht, wodurch sich die Effizienz der Funktion deutlich erhöht.
\begin{equation} \label{eqn:4-14}
\tag{4-14}
O(n \,\cdotp |V_{C_{i}}|) \,\cdotp O(|V_{C_{i}}|) \,\cdotp O(l) = O(n \,\cdotp l \,\cdotp |V_{C_{i}}|^2)
\end{equation}

\subsubsection{Laufzeit der Bestimmung der Likelihood aller Allele-Fractions} 

Nach der Berechnung der Allele-Fractions in $O(n \, \cdotp e^n)$ werden die zuvor beschriebenen Likelihoodberechnungen der Read-Allel-Paare in \lstinline|noderad_main.py| für alle Allele-Fractions ausgeführt. Die Likelihoodberechnungen werden also insgesamt $ e^n $ Mal wiederholt. Dabei kann nun zwischen der deutlich günstigeren Dictionary-Suche und den Suchvorgängen über alle Nachbarknoten mit Likelihoodberechnung in \lstinline|get_allele_likelihood_read()| differenziert werden. Wie bereits beschrieben wird die aufwändige Suche über die Nachbarn nur $ O(n \,\cdotp |V_{C_{i}}|) $ Mal ausgeführt bis das Dictionary vollständig ist. Im Anschluss wird nur noch das Dictionary durchsucht. Über alle Allele-Fractions ergibt sich unter Berücksichtigung dieses Aspekts nach Formel \eqref{eqn:4-15} eine Laufzeit von $ O( e^n n |V_{C_{i}}| + l n^2 |V_{C_{i}}|^3) $ für die Likelihoodberechnung über alle Allele-Fractions.
\begin{equation} \label{eqn:4-15}
\tag{4-15}
\begin{aligned}
O(n \, \cdotp e^n) + O(e^n &\ {} - n \,\cdotp |V_{C_{i}}|) \,  \cdotp O(n \,\cdotp |V_{C_{i}}|) + O(n \,\cdotp |V_{C_{i}}|) \, \cdotp O(n \,\cdotp l \,\cdotp |V_{C_{i}}|^2)\\
&\ = O(e^nn + e^n n |V_{C_{i}}| - n^2 |V_{C_{i}}|^2 + l n^2 |V_{C_{i}}|^3)\\
&\ = O(e^nn \, \cdotp(1 + |V_{C_{i}}|) - n^2 |V_{C_{i}}|^2 + l n^2 |V_{C_{i}}|^3)\\
&\ \in O(e^nn |V_{C_{i}}| - n^2 |V_{C_{i}}|^2 + l n^2 |V_{C_{i}}|^3)\\
&\ = O( e^n n |V_{C_{i}}| + n^2 |V_{C_{i}}|^2 \,\cdotp (l \,\cdotp|V_{C_{i}}| - 1))\\
&\ \in O( e^n n |V_{C_{i}}| + l n^2 |V_{C_{i}}|^3) 
\end{aligned}
\end{equation}

Bei der anschließenden Maximumssuche addiert sich zur Laufzeit noch eine Iteration über alle Allele-Fractions. Die Laufzeit ändert sich hierdurch nicht, da bereits $e^n n |V_{C_{i}}|$ die dominiert (siehe Formel \eqref{eqn:4-16}). Somit erfordert die Bestimmung der Allele-Fraction mit maximaler Likelihood insgesamt eine Laufzeit von $ O( e^n n |V_{C_{i}}| + l n^2 |V_{C_{i}}|^3) $.
\begin{equation} \label{eqn:4-16}
\tag{4-16}
\begin{aligned}
 O( n |V_{C_{i}}| &\ {} \,\cdotp (e^n + ln)) + O(e^n) \\
&\ = O( e^n n |V_{C_{i}}| + l n^2 |V_{C_{i}}|^3 + e^n)\\
&\ = O( e^n \,\cdotp ( n |V_{C_{i}}| + 1) + l n^2 |V_{C_{i}}|^3) \\
& \ \in O( e^n n |V_{C_{i}}| + l n^2 |V_{C_{i}}|^3) 
\end{aligned}
\end{equation}

Im Worst Case entspricht die Anzahl der Kandidatenallele genau der Anzahl der Reads in der Zusammenhangskomponente und es gilt $ n = |V_{C_{i}}| $, so dass die Laufzeit dann auf $  O( e^{|V_{C_{i}}|} \, \cdotp  |V_{C_{i}}|^2 + l \, \cdotp |V_{C_{i}}|^5) $ geschätzt werden kann \eqref{eqn:4-17}.
\begin{equation} \label{eqn:4-17}
\tag{4-17}
\begin{aligned}
&\ {} O( e^n n |V_{C_{i}}| + l n^2 |V_{C_{i}}|^3) \\
&\ {} = O( e^{|V_{C_{i}}|} \, \cdotp  |V_{C_{i}}|^2 + l \, \cdotp |V_{C_{i}}|^5)\\
\end{aligned}
\end{equation}

Die Laufzeit wird also durch die Anzahl der Allel-Fractions dominiert und kann bei großen Clustern und bei Clustern mit vielen Kandidatenallelen problematisch werden. Die konfigurierbaren Schwellenwerte \lstinline|treshold-cluster-size| sowie \lstinline|large-clusters| und \lstinline|small-clusters| aus \lstinline|treshold-seq-noise| ermöglichen eine Anpassung solcher Cluster, um die Anzahl der Kombinationen und damit den Rechenaufwand flexibel reduzieren zu können.


\section[Laufzeit der Loci-Zuordnung]{Laufzeit zur Bestimmung der Loci mit maximaler Likelihood}

======================= draft =======================\\

\subsubsection{Laufzeit zur Bestimmung der möglicher Loci-Kombinationen}

Wie bereits in Kap. \ref{subsubsec:cand_vafs} besprochen, benötigt die Generierung aller Allelkombinationen eine Laufzeit von $ O(e^n) $, wobei $n = n_{cand}$ die Anzahl der beobachteten Allele der Zusammenhangskomponente ist. Für diese Kombinationen werden jeweils alle $n!$ Permutationen gebildet, also mit einer Laufzeit von $ O(n!) $. Für jede Permutation erfolgt über ihre jeweilige Länge die Gruppierung zu den Loci. Die Länge jeder Permutation kann wegen der Funktion \lstinline|get_max_parsimony_n_alleles()| (vgl. Kap. \ref{subsec:cand_allele}) maximal $ n_{alleles} = n_{cand} + \phi - 1 $ betragen. Wegen $\phi = const$ beträgt die Laufzeit hier also $O(n_{cand}) = O(n)$. Die Sortierung bei Python erfordert eine Laufzeit von $ O(n\, \cdotp log(n))$ \cite{python-sort}. Die beiden Sortiervorgänge erfolgen zum einen über jeden Locus mit der Länge $\phi$ entsprechend seiner Ploidie und über alle Loci innerhalb der Permutation. Die Anzahl der Loci entspricht $\frac{n}{\phi}$, dadurch ergeben sich für die Sortiervorgänge Laufzeiten von $ O(\phi\, \cdotp log(\phi)) $ bzw. $ O\left( \frac{n}{\phi}\, \cdotp log\left( \frac{n}{\phi}\right) \right) $. Unter Berücksichtigung, dass $\phi = const$ gilt, beträgt die Laufzeit für \lstinline|get_candidate_loci()| insgesamt $ O(e^n \, \cdotp n! \, \cdotp n^2 \, \cdotp log(n)) $.
\begin{equation} \label{eqn:4-21}
\tag{4-21}
\begin{aligned}
&\ {}O(e^n) \, \cdotp O(n!) \, \cdotp O(n) \, \cdotp O(\phi\, \cdotp log(\phi))\, \cdotp O\left( \frac{n}{\phi}\, \cdotp log\left( \frac{n}{\phi}\right) \right)  \\
&\ =O\left( e^n \, \cdotp n! \, \cdotp n\, \cdotp \phi\, \cdotp log(\phi)\, \cdotp  \frac{n}{\phi}\, \cdotp log\left( \frac{n}{\phi} \right)\right)   \\
&\ =O\left( e^n \, \cdotp n! \, \cdotp n^2 \, \cdotp log(\phi)\, \cdotp  log\left( \frac{n}{\phi} \right)\right)   \\
&\ \in O(e^n \, \cdotp n! \, \cdotp n^2 \, \cdotp log(n))
\end{aligned}
\end{equation}
\\
Große Cluster sind hier also hinsichtlich der Laufzeit und des Speicherbedarfs noch problematischer als bei der Generierung der Allelkombinationen in der Funktion \linebreak \lstinline|get_candidate_vafs()| (Kap. \ref{subsubsec:cand_vafs}). Eine sinnvolle Anpassung der Grenzwerte \linebreak \lstinline|treshold-cluster-size| und   \lstinline|treshold-seq-noise| ermöglicht diesbezüglich eine Verbesserung. Allerdings ist an dieser Stelle ein effizienterer Ansatz zur Bestimmung der Loci-Kombinationen möglich, der in diesem Protoypen zwar keine Anwendung fand, aber für die spätere Implementierung in Rust von Bedeutung sein könnte. Dieser Ansatz wird im Ausblick in Kap. \ref{sec:ausblick} kurz beschrieben.

\subsubsection{Laufzeit für die Bestimmung der Loci-Kombination mit maximaler Likelihood}

\subsubsection{Laufzeit der Funktion \lstinline|get_cigar_tuples()|}

Die hierfür erforderliche Laufzeit setzt sich zusammen aus den Suchvorgengen für die beiden Knotenmengen $ R_{source} $ und $ R_{target} $, diese ist in graph-tool in $O(V_{c} + V_{c}) = O(V_{c})$ durchführbar (Kap. \ref{subsec:edges}). Seien im Worst Case die Hälfte aller Knoten der Zusammenhangskomponente in $ R_{source} $ und die andere Hälfte in $ R_{target} $. Um die Eigenschaft der Zusammenhangskomponente zu gewährleisten muss daher eine Kante zwischen beiden Knotenmenge existieren. Sei dies zudem eine entgegen gerichtete Kante. Sind die beiden Knoten $ (v, w) $ dieser Kante allerdings jeweils an letzter Position in $ R_{source} $ und $ R_{target} $, so erfolgen für alle übrigen Knoten der Komponente Kantenaufrufe für die Hin- und Rückrichtung. Wie bereits oben beschrieben, benötigt ein Kantenaufruf eine Laufzeit von $ O(\min (d(v), d(w)))$, mit den Knotengraden $d(v) $ von Knoten $v \in R_{source}$ und $ d(w) $ von Knoten $ w \in R_{target} $ ~\cite{docs_graph_tool}. Seien nun außerdem $ v $ mit allen Knoten in $ R_{source} $ und $ w $ mit allen Knoten in $ R_{target} $ verbunden, so besitzt $v$ einen Knotengrad von $ d(v) = \frac{V_{c}-1}{2} $. Der Knoten $ w $ besitzt einen Knotengrad von $ d(w) = \frac{V_{c}}{2} $, da eine entgegen gerichtete Kante von $w$ zu $v$ verläuft. Dann ergibt sich nach \eqref{eqn:4-18} eine Gesamtlaufzeit für \lstinline|get_cigar_tuples()| von $ O(V_{c}^3) $. \\

\begin{equation} \label{eqn:4-18}
\tag{4-18}
\begin{aligned}
&\ {} O(V_{c}) + O(V_{c}^2 \, \cdotp \min (d(v), d(w)))  \\
& \ = O\left( V_{c} + V_{c}^2 \, \cdotp \min \left( \frac{V_{c}-1}{2}\,, \frac{V_{c}}{2}\right) \right) \\
&\ = O(V_{c} + V_{c}^2 \, \cdotp V_{c}) \\
&\ = O(V_{c}^3) \\
\end{aligned}
\end{equation}

 \label{subsec:loc_compl}
Die Gesamtlaufzeit ergibt sich wiederum aus den einzelnen Laufzeiten der oben beschriebenen Funktionen. Diese Funktionen werden über allen Permutationen der Allelkombinationen in \lstinline|noderad_main.py| aufgerufen, wodurch die Laufzeit um den Faktor $ O(e^n \, \cdotp n!)$ steigt (vgl. Kap. \ref{subsec:comb_loci}). Die Indikatorfunktion prüft die Bedingung über die gesamte Länge einer der Permutationen und benötigt somit eine Laufzeit von $ O(n) $. Anschließend wird in \lstinline|calc_loci_likelihoods()| über alle Loci einer Permutation in $ O(\frac{n}{\phi}) $ iteriert und die Funktion \lstinline|get_allele_likelihood_allele()| aufgerufen. Diese ermittelt bei jedem Locus in $O(\phi) $ die Kombinationen ohne Wiederholung und ohne Beachtung der Reihenfolge. Nach \eqref{eqn:3-2} und \eqref{eqn:4-13} erhöhen die Kombinationen dabei die Laufzeit um den Faktor $ O(\binom{n}{2}) \in O(e^n) $. Die Bestimmung der CIGAR-Tupel für jede Kombination vergrößert die Laufzeit zusätzlich um den Faktor $O(V_{c}^3)$ (siehe Kap. \ref{subsec:lh_allele}). Über die CIGAR-Tupel wird schließlich für jede Base die Likelihood aus den Heterozygotiewahrscheinlichkeiten berechnet, analog zur Likelihoodberechnung zweier Reads in Kap. \ref{subsec:edges} kann dies mit $O(\overline{k}) $ veranschlagt werden, wobei $\overline{k}=const$ gilt. Da für alle Permuationen der Kombinationen die Berechnung Likelihood erfolgt, wird die anschließende Maximumsbestimmung über deren Anzahl also in $O(e^n\, \cdotp n!) $ durchgeführt.\\

Nach \eqref{eqn:4-22} ergibt sich damit für die Berechnung der wahrscheinlichsten Loci-Kombination insgesamt eine Laufzeit von $ O(e^n \, \cdotp n! \, \cdotp V_{c}^3)$.
\begin{equation} \label{eqn:4-22}
\tag{4-22}
\begin{aligned}
&\ {}O(e^n \, \cdotp n!) \, \cdotp \left( O(n) + O\left( \frac{n}{\phi} \right) \, \cdotp O(\phi) \, \cdotp O(e^n)  \, \cdotp O(V_{c}^3) \, \cdotp O(\overline{k})\right) + O(e^n\, \cdotp n!) \\
&\ =O(e^n \, \cdotp n! \, \cdotp(n + n \, \cdotp e^n \, \cdotp V_{c}^3)+ e^n\, \cdotp n!)  \\
&\ =O(e^n \, \cdotp n! \, \cdotp n + e^{2n} \, \cdotp n! \, \cdotp n \, \cdotp V_{c}^3)\\
&\ =O(e^{2n} \, \cdotp n! \, \cdotp n \, \cdotp V_{c}^3)\\
&\ \leq O(e^{2n} \, \cdotp n! \, \cdotp (n + 1) \, \cdotp V_{c}^3)\\
&\ = O(e^{2n} \, \cdotp (n + 1)! \, \cdotp V_{c}^3)\\
&\ \in O(e^n \, \cdotp n! \, \cdotp V_{c}^3)\\
\end{aligned}
\end{equation}

Wie bereits in Kap. \ref{subsec:al_compl} durchgeführt, soll auch hier der Worst Case betrachtet werden, bei dem die Anzahl der Kandidatenallele genau der Anzahl der Reads in der Zusammenhangskomponente entspricht, also $ n = n_{cand} =V_{c} $. Dann ergibt sich für die Berechnung der wahrscheinlichsten Loci-Zuordnung nach \eqref{eqn:4-23} eine maximale Laufzeit von $ O(e^{V_{c}} \, \cdotp V_{c}!) $.
\begin{equation} \label{eqn:4-23}
\tag{4-23}
\begin{aligned}
O(e^n \, \cdotp n! \, \cdotp V_{c}^3)
&\ {}=O(e^{V_{c}} \, \cdotp V_{c}! \, \cdotp V_{c}^3)\\
&\ \leq O(e^{V_{c}} \, \cdotp V_{c}! \, \cdotp (V_{c} + 1)\, \cdotp (V_{c} + 2)\, \cdotp (V_{c} + 3))\\
&\ =  O(e^{V_{c}} \, \cdotp (V_{c} + 3)!)\\
&\ \in O(e^{V_{c}} \, \cdotp V_{c}!)\\
\end{aligned}
\end{equation}

Die Anzahl der Permutationen dominiert durch $ O(V_{c}!) $ die Laufzeit noch stärker als bei der Ermittlung der Allelkombinationen in Kap. \ref{subsec:al_compl}. Dies ist für große Cluster sehr problematisch. Die Anpassung der Schwellenwerte \lstinline|treshold-cluster-size| und \linebreak \lstinline|threshold-seq-noise| können dies zwar in einem gewissen Rahmen für den Prototyp kompensieren. Bei der späteren Implementierung in Rust sollte hier jedoch ein effizienterer Ansatz gewählt werden. Eine effizientere Vorgehensweise diesbezüglich wird in Kap. \ref{sec:ausblick} vorgestellt.

\section{Abschließende Laufzeitanalyse des gesamten Algorithmus}

Für jeden Konstruktions- und Berechnungsschritt wurden die Laufzeiten bereits an entsprechender Stelle angesprochen. Zusammenfassend ergab sich dabei für die einmalige Konstruktion des Graphen und die Extraktion seiner Zusammenhangskomponenten $ C $ eine Laufzeit von $O(V \, \cdotp (V + E))$ (Kap. \ref{subsec:graph_compl}). Für jede Zusammenhangskomponente erfolgte die Berechnung der wahrscheinlichsten Allelkombination in $O(e^V_{c} \, \cdotp V_{c}^5)$ (Kap. \ref{subsec:al_compl}) und die Berechnung der wahrscheinlichsten Loci-Zuordnung in $ (e^V_{c} \, \cdotp V_{c}!) $ (Kap. \ref{subsec:loc_compl}). Die Laufzeiten können also wie folgt zusammengefasst werden:
\begin{equation} \label{eqn:4-24}
\tag{4-24}
\begin{aligned}
&\ {}O(V \, \cdotp (V + E)) + O\left( \sum_{c=1}^{|C|} (e^{V_{c}} \, \cdotp V_{c}^5 + e^{V_{c}} \, \cdotp V_{c}!)\right) \\
&\ = O\left( V \, \cdotp (V + E) +  \sum_{c=1}^{|C|} (e^{V_{c}} \, \cdotp V_{c}^5) + \sum_{c=1}^{|C|} (e^{V_{c}} \, \cdotp V_{c}!)\right)\\
&\ \in \left( O\sum_{c=1}^{|C|} (e^{V_{c}} \, \cdotp V_{c}!)\right)\\
\end{aligned}
\end{equation}

Besitzt im Worst Case der Graph nur eine einzige Zusammenhangskomponente, welche alle Knoten des Graphen enthält, so dass gilt $ |C|=1 $ und $ V_{c} = V $ so würde sich hieraus eine maximale Laufzeit von $ O(e^V \, \cdotp V!) $ ergeben.
\let\cleardoublepage\clearpage