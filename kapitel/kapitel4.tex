% kapitel4.tex
\definecolor{light-gray}{gray}{0.93}
\chapter{Laufzeitanalyse} \label{sec:}

\section[Laufzeit für Graph und Zusammenhangskomponenten]{Laufzeit für die Graphkonstruktion und Bestimmung der Zusammenhangskomponenten} \label{sec:}
\subsubsection{Laufzeit für das Hinzufügen der Knoten des Graphen} \label{subsec:}
Die Laufzeit für das Hinzufügen eines Knotens (siehe Kap. \ref{subsec:nodes}) im Graphen $G=(V, \, E)$ beträgt nach der Dokumentation von graph-tool  $ O(1) $ \cite{docs_graph_tool}. Die Zuweisung der Knoteneigenschaften erfolgt ebenfalls in $ O(1) $. Über alle Reads, also über die resultierende Anzahl der Knoten $ |V| $ ergibt sich daraus eine Gesamtlaufzeit von $ O(|V|) $.\\

\subsubsection{Laufzeit für das Hinzufügen der Kanten des Graphen} \label{subsec:}

Das Hinzufügen einer Kante im Graphen (siehe Kap. \ref{subsec:edges}) benötigt laut graph-tool-Dokumentation \cite{docs_graph_tool} eine Laufzeit von $ O(1) $. Da aber die Query- und die Referenzreads aus dem Alignment den zuvor angelegten Knoten zugeordnet werden müssen, erfordert dies eine Suche der betreffenden Knoten im Graphen. Dabei durchsucht graph-tool mit seiner Funktion \lstinline|find_vertex()| nur die Knoten und prüft auf die gesuchte Read-ID aus dem FASTQ-File. Die ein- und ausgehenden Kanten der Knoten werden nicht beachtet, so dass eine Tiefen- oder Breitensuche des Graphen nicht notwendig ist und die Suche in $ O(|V|) $ durchgeführt werden kann ~\cite{graph_tool_coplexity_find_vertex}. Die Zuweisung der Kanteneigenschaften erfolgt jeweils in $ O(1) $, da diese direkt bei der Erzeugung der Kante hinzugefügt werden und keine vorherige Suche der Kante erforderlich ist. Für alle Kanten ergibt sich daraus eine Gesamtlaufzeit von $ O(|E|\, \cdotp |V|) $. \\


\subsubsection{Laufzeit zur Bestimmung der Zusammenhangskomponenten} \label{subsec:}

Die Bestimmung der Zusammenhangskomponenten $C = (C_{1}, \dots , C_{h})$ durch graph-tool kann in $ O(|V| + |E|) $ durchgeführt werden \cite{docs_graph_tool}, hierbei wird jedem Konten die Indexnummer seiner Zusammenhangskomponente zugewiesen (siehe Kap. \ref{subsec:comp}). Aus Zusammenhangskomponenten mit mehr als einem Knoten sollen hiernach eigenständige Subgraphen erzeugt werden. Dazu wird in der Funktion \lstinline|get_components()| des Moduls \lstinline|graph_operations.py| zunächst ein nach den Knoten der Komponente gefilterter View des Gesamtgraphen erzeugt, welcher anschließend als neuer eigenständiger Graph initialisiert wird. Da beim Filtervorgang jeder Zusammenhangskomponente jeweils alle Knoten des Graphen betrachtet werden müssen, beträgt die Laufzeit hierfür $ O(h \, \cdotp |V|) $, wobei $h$ die Anzahl der Zusammenhangskomponenten ist. \\

Die Subgraphen der Zusammenhangskomponenten werden als Elemente einer Liste zusammengefasst. Durch das Erstellen einer Liste von Subgraphen kann später eine einfache Iteration über die Komponenten in $ O(h) $ ausgeführt werden, ohne dass der Filtervorgang über alle Knoten jeder Komponente wiederholt werden muss. \\

Die Gesamtlaufzeit für die Bestimmung der Zusammenhangskomponenten und die Generierung eigenständiger Subgraphen beträgt nach Formel \eqref{eqn:4-1} somit $ O(h \, \cdotp |V| + |E|) $. 
\begin{equation} \label{eqn:4-1}
\tag{4-1}
\begin{aligned}
 O(h \, \cdotp |V|) \, + \, O(|V| + |E|) &\ {} = O(|V| \, \cdotp (h + 1) +|E|)\\
 &\ = O(h \, \cdotp |V| + |E|)
 \end{aligned}
\end{equation}

Bei realen Daten gibt es in der Regel deutlich mehr Knoten als Cluster bzw. Zusammenhangskomponenten, so dass gilt $ h < |V| $. Würde im Worst Case aber jede Zusammenhangskomponente aus nur einem Knoten bestehen, also $ h = |V| $, so kann die maximale Laufzeit auf $ O(|V|^2 + |E|) $ geschätzt werden (siehe Formel \eqref{eqn:4-2}).\\
\begin{equation} \label{eqn:4-2}
\tag{4-2}
\begin{aligned}
O(h \, \cdotp |V| + |E|) &\ {} = O(|V| \, \cdotp |V| + |E|)\\
&\ = O(|V|^2 + |E|) 
\end{aligned}
\end{equation}

\subsubsection{Gesamtlaufzeit der Konstruktion des Graphen und der Zusammenhangskomponenten} \label{subsec:graph_compl}
Aus den Laufzeiten für die Erzeugung der Knoten in $ O(|V|) $, das Hinzufügen der Kanten in $ O(|E|\, \cdotp |V|) $  sowie die Bestimmung und Extraktion der Zusammenhangskomponenten in $ O(|V|^2 + |E|) $ ergibt sich nach \eqref{eqn:4-3} eine Gesamtlaufzeit von $ O(|V| \, \cdotp (|V| + |E|)) $. \\
\begin{equation} \label{eqn:4-3}
\tag{4-3}
\begin{aligned}
&\ {} O(|V|) + O(|E|\, \cdotp |V|) + O(|V|^2 + |E|) \\
&\ = O(|V| + |V|\, \cdotp |E| + |V|^2 + |E|)\\
&\ = O(|V|\, \cdotp (1 + |E|) + |V|^2 + |E|)\\
&\ \in O(|V|\, \cdotp |E| + |V|^2 + |E|)\\
&\ = O(|V|^2 + |E| \, \cdotp (1 + |V|))\\
&\ \in O(|V|^2 + |E| \, \cdotp |V|)\\
&\ = O(|V| \, \cdotp (|V| + |E|))\\
\end{aligned}
\end{equation}

\section[Laufzeitberechnung der VAFs mit maximaler Likelihood]{Laufzeit zur Bestimmung der Allele-Fractions mit maximaler Likelihood}

Da alle weiteren Schritte für jede Zusammenhangskomponente $C_{i} \in \{C_{1}, \dots , C_{h}\}$ durchgeführt werden, sollen hier zunächst die Laufzeiten für eine Komponente betrachten werden und erst am Ende des Kapitels die Laufzeit für alle Komponenten bestimmt werden. Die Zusammenhangskomponenten sind Subgraphen des Gesamtgraphen $G=(V, \, E)$, so dass gilt $ C_{i} \subseteq G$ und $C_{i}=(V_{C_{i}}, \, E_{C_{i}})$. Sei also im Folgenden $|V_{C_{i}}|$ die Anzahl der Knoten innerhalb einer Komponente. \\ 

\subsubsection{Laufzeit der Funktion \lstinline|get_candidate_alleles()|}
Für das Erstellen der Liste von Kandidatenallelen muss jeder Knoten einer Zusammenhangskomponente betrachtet werden, so dass der Vorgang in $ O(|V_{C_{i}}|) $ durchführbar ist.\\

\subsubsection{Laufzeit der Funktion \lstinline|get_max_parsimony_n_alleles()|}
Die Anpassung der Anzahl der Allele an die gegebene Ploidie kann für jede Komponente in $ O(1) $ erfolgen.\\

\subsubsection{Laufzeit der Funktion \lstinline|get_candidate_vafs()|} \label{subsubsec:cand_vafs}
%\subsubsection{Abschätzung der oberenen Laufzeitschranke bei Kombinationen mit %Wiederholung und Laufzeit der Funktion \lstinline|get_candidate_vafs()|} 
Für die Bestimmung der Allelkombinationen werden durch Verwendung von \linebreak \lstinline|itertools.combinations_with_replacement()| alle Kombinationen der Kandidatenallele generiert, wobei Wiederholungen erlaubt sind. Da kombinatorische Problemstellungen zu hohen Laufzeiten und deutlichem Speicherplatzbedarf führen, sind sie oft der dominierende und ggf. auch limitierende Schritt eines Programms. Daher soll an dieser Stelle eine genauere Laufzeitabschätzung erfolgen. \\

Seien $k$ die Anzahl der Kandidatenallele und $n$ die Anzahl der Allele, die bei gegebener Ploidie nach \lstinline|get_max_parsimony_n_alleles()| zu erwarten sind, und es gilt $n, k \in \mathds{N} $.  Wie bereits in Kap. \ref{subsec:cand_allele} beschrieben, lässt sich die Anzahl aller Kombinationen mit Zurücklegen aus dem Binomialkoeffizienten nach  Formel \eqref{eqn:3-1} errechnen \cite{tb_stat}. Das bedeutet, dass für jede Zusammenhangskomponente $ \binom{n + k - 1}{k} $ Kombinationen jeweils in O(1) gebildet werden müssen. Die Laufzeit zum Erzeugen aller Kombinationen mit Zurücklegen entspricht somit genau ihrer Anzahl, so dass je Zusammenhangskomponente eine Laufzeit von $ O(\binom{n + k - 1}{k}) $ benötigt wird. Ebenso wird jede spätere Iteration über der Menge der aus den Allelkombinationen gebildeten Allele-Fractions die Laufzeit um den Faktor $ O(\binom{n + k - 1}{k}) $ erhöhen. Daher soll diese Laufzeit hinsichtlich ihrer oberen Schranken im Folgenden genauer abgeschätzt werden. \\

Die allgemeine Formel des Binomialkoeffizienten \eqref{eqn:4-4} beschreibt die Anzahl aller Kombinationen ohne Zurücklegen. 
\begin{equation} \label{eqn:4-4}
\tag{4-4}
\binom{n}{k} = \frac{n!}{(n-k)!\, \cdotp k!}
\end{equation} 
Aus ihr kann die hier benötigte Anzahl aller Kombinationen mit Zurücklegen, also  $ \binom{n + k - 1}{k} $, abgeleitet werden, wenn gilt $ m = n + k - 1 $:
\begin{equation} \label{eqn:4-5}
\tag{4-5}
\begin{aligned}
\binom{m}{k} &\ {} = \frac{m!}{(m - k)!\, \cdotp k!} 
= \frac{(n+k-1)!}{((n+k-1)-k)!\, \cdotp k!} \\
&\ = \frac{(n+k-1)!}{(n-1)!\, \cdotp k!} 
= \binom{n + k - 1}{k}
\end{aligned}
\end{equation}

Mit anderen Worten, Kombinationen mit Zurücklegen können auf zwei Arten interpretiert werden: es werden aus n Elementen $ k $ Elemente mit Zurücklegen gezogen oder es werden aus $ n + k - 1 $ Elementen $ k $ Elemente ohne Zurücklegen gezogen. \\

Sei also für eine erste Laufzeitabschätzung $ m = n + k - 1 $, dann gilt:
\begin{equation} \label{eqn:4-6}
\tag{4-6}
\binom{m}{k} = \frac{m!}{(m - k)!\, \cdotp k!} \leq m!
\end{equation} 

Daraus ergibt sich nach \eqref{eqn:4-7} eine obere Schranke der Laufzeit von \linebreak $ O((n + k)!) $. 
\begin{equation} \label{eqn:4-7}
\tag{4-7}
O(m!) = O((n + k + 1)!) = O((n + k)!)
\end{equation} 

Hierfür soll nun eine kleinere obere Schranke gefunden werden. Allgemein lässt sich die Fakultät näherungsweise durch die Stirlingsche Formel \cite{bronst} abschätzen:
\begin{equation} \label{eqn:4-8}
\tag{4-8}
n! \approx \left( \frac{n}{e} \right) ^n \, \cdotp \sqrt{2 \, \cdotp \pi \, \cdotp n}
\end{equation} 

Daraus folgt, dass \eqref{eqn:4-9} eine untere Schranke der Fakultät ist \cite{script_binom}.
\begin{equation} \label{eqn:4-9}
\tag{4-9}
n! \geq \left( \frac{n}{e} \right) ^n 
\end{equation} 

Durch die Formeln \eqref{eqn:3-1} und \eqref{eqn:4-9} lässt sich durch einige Umformungen die obere Schranke der Laufzeit von ursprünglich $ O(n!) $  auf $ O\left( \left( \frac{e \, \cdotp (n + k - 1)}{k}\right)^k\right) $ eingrenzen \cite{script_binom}:
\begin{equation} \label{eqn:4-10}
\tag{4-10}
\begin{aligned}
\binom{n + k - 1}{k} &\ {} \overset{\eqref{eqn:3-1}}{=}  \frac{(n+k-1)!}{(n-1)!\, \cdotp k!} = \frac{\prod\limits_{i=1}^{n+k-1}i}{\prod\limits_{i=1}^{n-1}i \; \cdotp \, \prod\limits_{i=1}^{k}i}  \\
&\ = \frac{\prod\limits_{i=n}^{n+k-1}i \; \cdotp \, \prod\limits_{i=1}^{n-1}i}{\prod\limits_{i=1}^{n-1}i \; \cdotp \, \prod\limits_{i=1}^{k}i} = \frac{\prod\limits_{i=n}^{n+k-1}i}{\prod\limits_{i=1}^{k}i}\\
&\ = \frac{(n + k - 1) \, \cdotp (n + k - 2)\, \cdotp \; \dots \; \, \cdotp n}{k!} \\
&\ \leq \frac{(n + k - 1)^k}{k!} \\
&\ \overset{\eqref{eqn:4-9}}{\leq} \frac{(n + k - 1)^k}{\left( \frac{k}{e} \right) ^k} \\
&\ = \left( \frac{e \, \cdotp (n + k - 1)}{k}\right)^k  \\
\end{aligned}
\end{equation} 

Diese obere Laufzeitschranke kann nun verwendet werden, um die Laufzeit im Worst Case zu bestimmen. Dazu soll zunächst der Worst Case selbst ermittelt werden. Da die Laufzeit der Anzahl der Kombinationen und damit dem Binomialkoefizienten entspricht, muss also ein möglichst großer Binomialkoeffizient gefunden werden, d.h. der Zusammenhang von $n$ und $k$ zueinander, so dass $\binom{n}{k}$ maximal wird.\\

Der Binomialkoeffizient verfügt über bestimmte Eigenschaften, insbesondere gelten der Symmetrie- \eqref{eqn:4-11} und der Additionssatz \eqref{eqn:4-12}, die sich auch in der Struktur des Pascalschen Dreiecks widerspiegeln \cite{bronst}. 
\begin{equation} \label{eqn:4-11}
\tag{4-11}
\binom{n}{k} = \binom{n}{n - k}
\end{equation} 
\begin{equation} \label{eqn:4-12}
\tag{4-12}
\binom{n}{k} + \binom{n}{k + 1} = \binom{n + 1}{k + 1} 
\end{equation} 
Aufgrund der Symmetrie sind die Binomialkoeffizienten jeder Zeile des Dreiecks $\binom{n}{k_{i}}$ mit $ k_{i} \in 1, \dots n $ und $ i \in \mathds{N} $ symmetrisch im Bezug auf die Zeilenmitte. Und da nach \eqref{eqn:4-12} jeder Koeffizient aus der Summe der beiden darüber liegenden Koeffizienten entsteht, sind die Werte der Koeffizienten zu den Zeilenrändern hin abnehmend und weisen in der Zeilenmitte ihr Maximum auf. Ist $n$ gerade, so befindet sich die Zeilenmitte bei $ k = \frac{n}{2} $. Ist $n$ ungerade so befinden sich die Maxima bei $ k = \lceil \frac{n}{2} \rceil $ und $ k = \lfloor \frac{n}{2} \rfloor $ und besitzen aufgrund der Symmetrie den gleichen Wert. Vereinfacht gilt also für ein gegebenes $n$, dass der Binomialkoeffizient $\binom{n}{k_{i}}$ bei $ k_{i} = \frac{n}{2} $ maximal ist. \\

Daher soll $ k = \frac{n}{2} $ als Worst Case angenommen werden, dann ergibt sich aus \eqref{eqn:4-10} eine Laufzeit von $ O(3e^{\frac{n}{2}} ) \in O(e^n) $. 
\begin{equation} \label{eqn:4-13}
\tag{4-13}
\begin{aligned}
\left( \frac{e \, \cdotp (n + k - 1)}{k}\right)^k &\ {} = \left( \frac{e \, \cdotp (n + \frac{n}{2} - 1)}{\frac{n}{2}}\right)^{\frac{n}{2}}  \\
&\ = \left( \frac{\frac{3en - 2e}{2}} {\frac{n}{2}}\right)^{\frac{n}{2}} \\
&\ = \left( \frac{3en - 2e}{n}\right)^{\frac{n}{2}} \\
&\ \leq \left( \frac{3en}{n}\right)^{\frac{n}{2}}\\
&\ = 3e^{\frac{n}{2}} \\
&\ \in O(e^n)\\
\end{aligned}
\end{equation}
Hinsichtlich der Allelkombinationen entspricht dies einer Zeit von $ O(e^n) $ für jede Zusammenhangskomponente.  \\

Für sehr große Cluster und Cluster mit vielen Varianten ist daher die Laufzeit problematisch. Ebenso kommt es zu einem hohen Bedarf an Arbeitsspeicher, aufgrund der großen Anzahl von Kombinationen die dabei erzeugt werden. Um dies bedingt kompensieren zu können, wurden die bereits beschriebenen Schwellenwerte eingeführt, die ober- und unterhalb einer festgelegten Clustergröße nur Kandidatenallele ab einer bestimmten Häufigkeit ihrer Sequenz in den Reads berücksichtigen (vgl. Kap. \ref{subsec:cand_allele}).\\

Bei der Berechnung der Allele-Fractions wird für jede Allelkombination die Häufigkeit der Kandidatenallele im Bezug auf die Allelkombination ermittelt. Es werden also alle $n$ Positionen jeder Kombination betrachtet, so dass die Laufzeit der Funktion \lstinline|get_candidate_vafs()| insgesamt $ O(n\, \cdotp e^n)$ beträgt. 

\subsubsection{Laufzeit der Funktion \lstinline|get_alignment_likelihood()|}

Für die Berechnung der Likelihood eines Read-Kandidatenallel-Paares wird die geschätzte Fehlerrate $ p_{query} $ jeder Base des Reads verwendet. Durch die Verwendung der CIGAR-Tupel werden die Likelihoodberechnungen meist gebündelt für mehrere Basen mit gleicher Operation (Match, Substitution, Insertion, Deletion) durchgeführt. Dennoch müssen vorab für alle Basen des Reads die Werte von $ p_{query} $ aus den Phred Quality Scores nach \eqref{eqn:3-3} ermittelt werden. Daher kann die Laufzeit für die Likelihoodberechnung eines Reads über die durchschnittliche Readlänge $ l $ geschätzt werden und beträgt somit $O(l)$.


\subsubsection{Laufzeiten der Funktionen \lstinline|calc_vafs_likelihood()|, \lstinline|calc_vafs_likelihood_read()| und \lstinline|get_allele_likelihood_read()|}

Durch die Funktion \lstinline|calc_vafs_likelihood()| wird über alle Reads in $ O(|V_{C_{i}}|) $ und durch \lstinline|calc_vafs_likelihood_read()| über alle Kandidatenallele iteriert. Es gilt $n \geq k$, da die Anzahl der Kandidatenallele maximal so groß sein kann wie die tatsächliche Anzahl der Allele nach Berücksichtigung der Ploidie, dadurch kann für \lstinline|calc_vafs_likelihood_read()| die obere Laufzeitschranke mit $ O(n) $ veranschlagt werden. Die aus den beiden Funktionen generierten paarweisen Kombinationen der Kandidatenallele mit allen Reads werden an \linebreak \lstinline|get_allele_likelihood_read()| weitergereicht.\\

Dort wird zunächst das angelegte Dictionary nach bereits vorhandenen Einträgen durchsucht. Da hier maximal ein Eintrag für jedes Kandidatenallel zu jedem Read vorliegen kann, benötigt die Suche $ O(n \,\cdotp |V_{C_{i}}|) $ \cite{python-sort}. \\

Liegt kein Eintrag vor, so werden zunächst die ausgehenden Nachbarn durchsucht, und bei erfolgloser Suche, werden im Anschluss die eingehenden Nachbarn betrachtet. Die Anzahl der maximalen Suchvorgänge entspricht also der Summe der aus- und eingehenden Kanten des Reads. Somit entspricht die Laufzeit hierfür seinem Knotengrad $d$. Im Worst Case wäre die Zusammenhangskomponente ein vollständiger gerichteter Graph, so dass $ d = |V_{C_{i}}| - 1 $. Somit beträgt die Laufzeit für die Suchvorgänge maximal $O(|V_{C_{i}}|)$.\\

Die Suchvorgänge aus \lstinline|get_allele_likelihood_read()| werden genau so oft ausgeführt, bis alle Einträge im Dictionary erzeugt wurden, also $n \,\cdotp |V_{C_{i}}|$ Mal. Für jeden Eintrag ins Dictionary wird dann die Likelihood in $ O(l) $ errechnet. Daraus ergibt sich schließlich eine Laufzeit für die Suchvorgänge und die Likelihoodberechnungen von $ O(n \,\cdotp l \,\cdotp |V_{C_{i}}|^2)$ (siehe Formel \eqref{eqn:4-14}). Hiernach wird nur noch das Dictionary in $ O(n \,\cdotp |V_{C_{i}}|) $ durchsucht, wodurch sich die Effizienz der Funktion deutlich erhöht.
\begin{equation} \label{eqn:4-14}
\tag{4-14}
O(n \,\cdotp |V_{C_{i}}|) \,\cdotp O(|V_{C_{i}}|) \,\cdotp O(l) = O(n \,\cdotp l \,\cdotp |V_{C_{i}}|^2)
\end{equation}

\subsubsection{Laufzeit der Bestimmung der Likelihood aller Allele-Fractions} \label{subsubsec:complex-max-al-lh}

Nach der Berechnung der Allele-Fractions in $O(n \, \cdotp e^n)$ werden die zuvor beschriebenen Likelihoodberechnungen der Read-Allel-Paare in \lstinline|noderad_main.py| für alle Allele-Fractions ausgeführt. Die Likelihoodberechnungen werden also insgesamt $ e^n $ Mal wiederholt. Dabei kann nun zwischen der deutlich günstigeren Dictionary-Suche und den Suchvorgängen über alle Nachbarknoten mit Likelihoodberechnung in \lstinline|get_allele_likelihood_read()| differenziert werden. Wie bereits beschrieben wird die aufwändige Suche über die Nachbarn nur $ O(n \,\cdotp |V_{C_{i}}|) $ Mal ausgeführt bis das Dictionary vollständig ist. Im Anschluss wird nur noch das Dictionary durchsucht. Über alle Allele-Fractions ergibt sich unter Berücksichtigung dieses Aspekts nach Formel \eqref{eqn:4-15} eine Laufzeit von $ O( e^n\, \cdotp n\, \cdotp |V_{C_{i}}| + l\, \cdotp n^2\, \cdotp |V_{C_{i}}|^3) $ für die Likelihoodberechnung über alle Allele-Fractions.
\begin{equation} \label{eqn:4-15}
\tag{4-15}
\begin{aligned}
O(n \, \cdotp e^n) + O(e^n &\ {} - n \,\cdotp |V_{C_{i}}|) \,  \cdotp O(n \,\cdotp |V_{C_{i}}|) + O(n \,\cdotp |V_{C_{i}}|) \, \cdotp O(n \,\cdotp l \,\cdotp |V_{C_{i}}|^2)\\
&\ = O(e^n\, \cdotp n + e^n \, \cdotp n \, \cdotp |V_{C_{i}}| - n^2 \, \cdotp |V_{C_{i}}|^2 + l \, \cdotp n^2\, \cdotp |V_{C_{i}}|^3)\\
&\ = O(e^n\, \cdotp n \, \cdotp(1 + |V_{C_{i}}|) - n^2 \, \cdotp |V_{C_{i}}|^2 + l\, \cdotp n^2 \, \cdotp |V_{C_{i}}|^3)\\
&\ \in O(e^n\, \cdotp n \, \cdotp |V_{C_{i}}| - n^2 \, \cdotp |V_{C_{i}}|^2 + l \, \cdotp n^2 \, \cdotp |V_{C_{i}}|^3)\\
&\ = O( e^n \, \cdotp n \, \cdotp |V_{C_{i}}| + n^2 \, \cdotp |V_{C_{i}}|^2 \,\cdotp (l \,\cdotp|V_{C_{i}}| - 1))\\
&\ \in O( e^n\, \cdotp n\, \cdotp |V_{C_{i}}| + l\, \cdotp n^2\, \cdotp |V_{C_{i}}|^3) 
\end{aligned}
\end{equation}

Bei der anschließenden Maximumsuche addiert sich zur Laufzeit noch eine Iteration über alle Allele-Fractions. Die Laufzeit ändert sich hierdurch nicht, da bereits $e^n\, \cdotp n\, \cdotp |V_{C_{i}}|$ dominiert (siehe Formel \eqref{eqn:4-16}). Somit erfordert die Bestimmung der Allele-Fraction mit maximaler Likelihood insgesamt eine Laufzeit von $ O( e^n\, \cdotp n\, \cdotp |V_{C_{i}}| + l\, \cdotp n^2\, \cdotp |V_{C_{i}}|^3) $.
\begin{equation} \label{eqn:4-16}
\tag{4-16}
\begin{aligned}
 O( n \, \cdotp |V_{C_{i}}| &\ {} \,\cdotp (e^n + l \, \cdotp n)) + O(e^n) \\
&\ = O( e^n \, \cdotp n \, \cdotp |V_{C_{i}}| + l \, \cdotp n^2 \, \cdotp |V_{C_{i}}|^3 + e^n)\\
&\ = O( e^n \,\cdotp ( n \, \cdotp |V_{C_{i}}| + 1) + l \, \cdotp n^2 \, \cdotp |V_{C_{i}}|^3) \\
& \ \in O( e^n \, \cdotp n\, \cdotp |V_{C_{i}}| + l\, \cdotp n^2\, \cdotp |V_{C_{i}}|^3) 
\end{aligned}
\end{equation}

Im Worst Case entspricht die Anzahl der Kandidatenallele genau der Anzahl der Reads in der Zusammenhangskomponente und es gilt $ n = |V_{C_{i}}| $, so dass die Laufzeit dann auf $  O( e^{|V_{C_{i}}|} \, \cdotp  |V_{C_{i}}|^2 + l \, \cdotp |V_{C_{i}}|^5) $ geschätzt werden kann (Formel \eqref{eqn:4-17}).
\begin{equation} \label{eqn:4-17}
\tag{4-17}
\begin{aligned}
&\ {} O( e^n\, \cdotp n \, \cdotp |V_{C_{i}}| + l \, \cdotp n^2 \, \cdotp |V_{C_{i}}|^3) \\
&\ {} = O( e^{|V_{C_{i}}|} \, \cdotp  |V_{C_{i}}|^2 + l \, \cdotp |V_{C_{i}}|^5)\\
\end{aligned}
\end{equation}

Die Laufzeit wird also durch die Anzahl der Allel-Fractions dominiert und kann bei großen Clustern und bei Clustern mit vielen Kandidatenallelen problematisch werden. Die konfigurierbaren Schwellenwerte \lstinline|treshold-cluster-size| sowie \lstinline|large-clusters| und \lstinline|small-clusters| aus \lstinline|treshold-seq-noise| ermöglichen eine Anpassung solcher Cluster, um die Anzahl der Kombinationen und damit den Rechenaufwand flexibel reduzieren zu können.


\section[Laufzeit der Loci-Zuordnung]{Laufzeit zur Bestimmung der Loci mit maximaler Likelihood}

\subsubsection{Laufzeit der Funktion \lstinline|get_candidate_loci()|}

Wie bereits in Kap. \ref{subsec:comb_loci} besprochen, wird die Indikatorfunktion nur für eine Allele-Fraction, die Allele-Fraction mit maximaler Likelihood, erfüllt. Diese wird, um die \linebreak Kandidaten-Loci zu ermitteln, in ihre ursprüngliche Allelkombination mit Wiederholungen zurückgerechnet. Dies erfordert eine Iteration über die Länge einer Allele-Fraction. Sei $k$ weiterhin die Anzahl der Kandidatenallele und somit die Länge einer Allele-Fraction und sei $n$ die Anzahl der zu erwartenden Allele und somit die Länge einer Allelkombination (vgl. Kap. \ref{subsubsec:cand_vafs}). Dann gilt nach Formel \eqref{eqn:2-8}, dass die Iteration über die Länge einer Allele-Fraction maximal eine Laufzeit von $O(k) \in O(n)$ erfordert, da $k \leq n$. Die anschließende Konstruktion der Allelkombination der Länge $n$ aus der Allele-Fraction erfolgt in $O(n)$. Wie in Satz \ref{thm:comb_indicator} bewiesen wurde, genügt es über dieser einen Allelkombination mit maximaler Likelihood die Permutationen zu bilden. Die Permutationen entsprechen dann allen Loci-Kombinationen, welche die Indikatorfunktion erfüllen. \\

Es werden also für eine Kombination der Länge $n$ alle $n!$ Permutationen gebildet, die Laufzeit hierfür beträgt somit $ O(n!) $, da \lstinline|itertools.permutations| auch in der Kombination wiederholt vorkommende Allele als jeweils eigenständige Items betrachtet \cite{itertools}. Dadurch entstehen Duplikate. Für die anschließende Gruppierung der Permutationen zu Loci-Kombinationen, muss jede Permutation entsprechend der gegebenen Ploidie $\phi$ in Loci aufgeteilt werden, so dass hier über die Länge der Permutation iteriert wird. Dies benötigt somit eine Laufzeit von $O(n  \, \cdotp n!)$. Hiernach werden zwei Sortiervorgänge ausgeführt. Einmal innerhalb der Loci, so dass sich die Laufzeit um den Faktor $O(\phi\, \cdotp \log\phi)$ erhöht und anschließend über die Loci innerhalb der Loci-Kombination in $ O\left( \frac{n}{\phi}\, \cdotp \log\left( \frac{n}{\phi}\right)\right)  $ \cite{python-sort}. Da $\phi = const.$ kann für die Bildung der Permutationen, ihre Gruppierung und Sortierung nach Formel \eqref{eqn:4-18} insgesamt eine Laufzeit von $O\left( n! \, \cdotp \log n \right) $ veranschlagt werden. \\
\begin{equation} \label{eqn:4-18}
\tag{4-18}
\begin{aligned}
O\left( n \, \cdotp n! \, \cdotp \frac{n}{\phi}\, \cdotp \log\left( \frac{n}{\phi}\right) \, \cdotp \phi\, \cdotp \log\phi\right) &\ {} =  O\left( n! \, \cdotp n^2 \, \cdotp \log\left( \frac{n}{\phi}\right) \, \cdotp \log(\phi)\right)\\
&\ \stackrel{\phi = const.}{=} O\left( n! \, \cdotp n^2 \, \cdotp \log n \right)\\
&\ \leq O((n + 2) \, \cdotp (n + 1) \, \cdotp n! \, \cdotp \log n ) \\
&\ = O( (n + 2)! \, \cdotp \log n)\\
&\ \in O(n ! \, \cdotp \log n)
\end{aligned}
\end{equation}

Das Entfernen der Duplikate ist in Python durch die \lstinline|set()| Operation effizient über Hash-Tabellen  möglich \cite{python-sort}. Hierfür wird jede Permutation nur einmal betrachtet, so dass die Duplikatentfernung in $O(n!)$ erfolgen kann. \\

Insgesamt ergibt sich also für die Generierung der Loci-Kombinationen nach Formel \eqref{eqn:4-19} eine Laufzeit von $ O(n!\, \cdotp \log n) $.
\begin{equation} \label{eqn:4-19}
\tag{4-19}
\begin{aligned}
O(n) + O(n) &\ {} + O(n!) + O(n ! \, \cdotp \log n) + O(n!) \\
&\ = O(2n + 2 n! + n ! \, \cdotp \log n) \\
&\ {} \in O(n + n! + n ! \, \cdotp \log n)\\
&\ {} \in O(n ! \, \cdotp \log n)\\
\end{aligned}
\end{equation}

Nach dem zugrundeliegenden Modell hätten für die Loci-Kombinationen alle Permutationen über allen Allelkombinationen erzeugt werden müssen. Dadurch wären insgesamt $(e^n)!$ Permutationen entstanden. Für jede dieser Permutationen hätte die Bedingung der Indikatorfunktion geprüft werden müssen. Es hätte somit eine Laufzeit von mindestens $\Omega((e^n)!)$ dominiert. Durch die Implementierung auf Grundlage von Satz \ref{thm:comb_indicator} konnte somit die Laufzeit $ O(n!\, \cdotp \log n) $ deutlich reduziert werden. Da hier nur noch $n!$ Permutationen erzeugt werden ist auch der Speicherplatzbedarf wesentlich geringer.

\subsubsection{Laufzeit der Funktion \lstinline|get_cigar_tuples()|}

Die Suchvorgänge für die beiden Knotenmengen $ R_{source} $ und $ R_{target} $ (Kap. \ref{subsec:lh_loci}) benötigen in graph-tool jeweils $O(|V_{C_{i}}|)$ \cite{graph_tool_coplexity_find_vertex}. Anschließend wird eine Vorwärts- oder Rückwärtskante zwischen beiden Knotenmengen gesucht, d.h. im Worst Case muss für jeden Knoten $ v \in R_{source} $ mit jedem Knoten aus $w \in R_{target} $ ein zweifacher Kantenaufruf erfolgen. Die Laufzeit eines Kantenaufrufs hängt in graph-tool vom Knotengrad $d$ der beteiligten Knoten ab. Seien $d(v)$ und $d(w)$ die Knotengrade der Knoten $v$ und $w$, so beträgt die Laufzeit für einen Kantenaufruf zwischen ihnen $ O(\min (d(v), d(w)))$ \cite{docs_graph_tool}. \\

Seien im Worst Case die Hälfte aller Knoten der Zusammenhangskomponente in $ R_{source} $ und die andere Hälfte bis auf einen Knoten $u$ in $ R_{target} $. Seien $ R_{source} $ und $ R_{target} $ jeweils vollständige gerichtete Subgraphen, die jeweils nur eine Kante zu $u$ besitzen. Dadurch sind $ R_{source} $ und $ R_{target} $ allein über $u$ mit einander verbunden und da $u \notin R_{source}$ und $u \notin R_{target}$, existiert keine direkte Kante, die $ R_{source} $ und $ R_{target} $ mit einander verbindet. In diesem Falle müssen also für alle $\frac{|V_{C_{i}}|}{2}$ Knoten aus $ R_{source} $ mit jeweils allen $\frac{|V_{C_{i}}|}{2}-1$ Knoten aus $R_{target}$ die Kantenaufrufe ausgeführt werden. Da $ R_{source} $ und $ R_{target} $ ohne den Knoten $u$ zwei jeweils von einander unabhängige vollständige Graphen sind, beträgt der Knotengrad bei jedem Kantenaufruf für $d(v) = \frac{|V_{C_{i}}|}{2}$ und für $d(w) = \frac{|V_{C_{i}}|}{2} -1$. Nach Formel \eqref{eqn:4-20} beträgt daher die Laufzeit von \lstinline|get_cigar_tuples()| im Worst Case $O(|V_{C_{i}}|^3)$. \\

\begin{equation} \label{eqn:4-20}
\tag{4-20}
\begin{aligned}
 O(|V_{C_{i}}|) + O(|V_{C_{i}}|) &\ {} + O\left( \frac{|V_{C_{i}}|}{2} \, \cdotp \left( \frac{|V_{C_{i}}|}{2} - 1\right) \, \cdotp \min \left(\frac{|V_{C_{i}}|}{2}, \frac{|V_{C_{i}}|}{2} -1 \right)   \right)   \\
& \ = O\left(2  \, \cdotp |V_{C_{i}}| +  \left( \frac{|V_{C_{i}}|}{2}\right)^2 \, \cdotp \left( \frac{|V_{C_{i}}|}{2} - 1\right) \right) \\
&\ \in O\left(|V_{C_{i}}| + \left( \frac{|V_{C_{i}}|}{2}\right)^3 \right)  \\
&\ \in O(|V_{C_{i}}|^3) \\
\end{aligned}
\end{equation}

\subsubsection{Laufzeiten der Funktionen \lstinline|indicator_constraint()|, \lstinline|calc_loci_likelihoods()|, \linebreak \lstinline|get_allele_likelihoods_allele()| und \lstinline|get_heterozygosity()| und Bestimmung der Gesamtlaufzeit der Loci-Zuordnung} \label{subsubsec:compl_loci_lh}

Die Prüfung der Bedingung der Indikatorfunktion erfolgt über alle Positionen einer Loci-Kombination in $O(n)$. Da aber nach Satz \ref{thm:comb_indicator} diese Prüfung nicht mehr notwendig ist, soll ihre Laufzeit in der weiteren Laufzeitanalyse keine Berücksichtigung finden. \\

Die eigentliche Likelihoodberechnung erfolgt schließlich über die Readlänge der Allelpaare jedes Locus aller $n!$ Loci-Kombination der Allele-Fraction mit maximaler Likelihood. Wie schon bei den Allele-Fractions werden die Ergebnisse der Likelihoodberechnungen in einem Dictionary abgelegt. Dadurch müssen von allen $n!$ Loci-Kombinationen nur für $\binom{n}{2}$ Allelkombinationen die Likelihoodberechnungen mit Ermittlung der CIGAR-Tupel über \lstinline|get_cigar_tuples()| durchgeführt. Für alle übrigen Loci-Kombinationen können dann die Werte dem Dictionary entnommen werden. \\

Zunächst kann der Laufzeitfaktor für die Allelkombinationen, also $\binom{n}{2}$, nach Formel \eqref{eqn:4-21} durch $O(n^2)$ abgeschätzt werden.
\begin{equation} \label{eqn:4-21}
\tag{4-21}
\begin{aligned}
 O\left( \binom{n}{2}\right) &\ {} = O\left( \frac{n!}{(n - 2)!\, \cdotp 2! }\right) \\
&\ = \frac{n \, \cdotp (n - 1) \, \cdotp (n - 2)!}{(n - 2)!\, \cdotp 2!} \\
&\ = \frac{n \, \cdotp (n - 1)}{2} \\
&\ \in O(n^2)
\end{aligned}
\end{equation}

Für die $\binom{n}{2}$ Berechnungen mit Ermittlung der CIGAR-Tupel und Likelihoodberechnung ergibt sich nach \eqref{eqn:4-22} eine Laufzeit von $ O( l\, \cdotp n^5  \, \cdotp |V_{C_{i}}|^3) $.
\begin{equation} \label{eqn:4-22}
\tag{4-22}
\begin{aligned}
&\ {} O\left( \binom{n}{2}\right)  \, \cdotp O\left(\frac{n}{\phi} \right) \, \cdotp O(|V_{C_{i}}|^3) \, \cdotp O(l)  \\
&\ \stackrel{\phi = const.}{=} O\left( \binom{n}{2} \, \cdotp n \, \cdotp |V_{C_{i}}|^3 \, \cdotp l \right) \\
&\ \stackrel{\eqref{eqn:4-21}}{=} O( n^2 \, \cdotp n \, \cdotp |V_{C_{i}}|^3 \, \cdotp l) \\
&\ = O( l\, \cdotp n^3  \, \cdotp |V_{C_{i}}|^3)\\
\end{aligned}
\end{equation}

Für die übrigen $n! - \binom{n}{2}$ Berechnungen kann der Eintrag dem Dictionary entnommen werden, so dass sich nach \eqref{eqn:4-23} eine Laufzeit von $O(n  \, \cdotp n!)$ ergibt.
\begin{equation} \label{eqn:4-23}
\tag{4-23}
\begin{aligned}
&\ {} O\left( n! - \binom{n}{2}\right)  \, \cdotp O\left(\frac{n}{\phi} \right)  \\
&\ \stackrel{\phi = const.}{=} O\left( \left( n! - \binom{n}{2}\right)  \, \cdotp n \right)\\
&\ \stackrel{\eqref{eqn:4-21}}{=} O((n! - n^2)  \, \cdotp n )\\
&\ = O( n \, \cdotp n! - n^3)\\
&\ \in O(n  \, \cdotp n!)\\
\end{aligned}
\end{equation}

Die Gesamtlaufzeit für die Loci-Zuordnung ergibt sich aus der Summe der Laufzeiten beider Berechnungsvarianten sowie der Bestimmung der Loci-Kombinationen und der Maximumsbestimmung über alle $n!$ Loci-Kombinationen mit $O( l\, \cdotp n^3  \, \cdotp |V_{C_{i}}|^3 + n  \, \cdotp n!)$. 
\begin{equation} \label{eqn:4-24}
\tag{4-24}
\begin{aligned}
&\ {} O( l\, \cdotp n^3  \, \cdotp |V_{C_{i}}|^3) + O(n  \, \cdotp n!) + O(n ! \, \cdotp \log n) + O(n!) \\
&\ \in O( l\, \cdotp n^3  \, \cdotp |V_{C_{i}}|^3 + n  \, \cdotp n!)
\end{aligned}
\end{equation}

Auch hier soll abschließend der Worst Case betrachtet werden, bei dem die Anzahl der Kandidatenallele genau der Anzahl der Reads in der Zusammenhangskomponente entspricht, also $ n = |V_{C_{i}}| $. Dann ergibt sich für die Berechnung der wahrscheinlichsten Loci-Zuordnung nach \eqref{eqn:4-25} eine maximale Laufzeit von $ O( l \, \cdotp |V_{C_{i}}|^6 + |V_{C_{i}}| \, \cdotp |V_{C_{i}}|!) $.
\begin{equation} \label{eqn:4-25}
\tag{4-25}
\begin{aligned}
&\ {} O( l\, \cdotp n^3  \, \cdotp |V_{C_{i}}|^3 + n  \, \cdotp n!)\\
&\ = O( l \, \cdotp |V_{C_{i}}|^6 + |V_{C_{i}}| \, \cdotp |V_{C_{i}}|!)
\end{aligned}
\end{equation}

Die Anzahl der Permutationen dominiert durch $ O(|V_{C_{i}}|!) $ die Laufzeit noch stärker als bei der Ermittlung der Allelkombinationen in Kap. \ref{subsubsec:complex-max-al-lh}. Dies ist für große Cluster bzw. für Cluster mit vielen Kandidatenallelen sehr problematisch. Die Anpassung der Schwellenwerte für \lstinline|treshold-cluster-size| und  \lstinline|threshold-seq-noise| können dies zwar in einem gewissen Rahmen für den Prototypen kompensieren. Bei der späteren Implementierung in Rust sollte hier die Anpassung der Schwellenwerte weiter optimiert werden (vgl. Kap. \ref{sec:ausblick}).

\section[Gesamtlaufzeit des Algorithmus]{Abschließende Laufzeitanalyse des gesamten Algorithmus}

Für jeden Konstruktions- und Berechnungsschritt wurden die Laufzeiten bereits an entsprechender Stelle angesprochen. Zusammenfassend ergab sich dabei für die einmalige Konstruktion des Graphen und die Extraktion seiner Zusammenhangskomponenten $ C $ eine Laufzeit von $O(|V| \, \cdotp (|V| + |E|)) $ (Kap. \ref{subsec:graph_compl}). Für jede Zusammenhangskomponente erfolgte die Berechnung der wahrscheinlichsten Allelkombination in $ O( e^n\, \cdotp n\, \cdotp |V_{C_{i}}| + l\, \cdotp n^2\, \cdotp |V_{C_{i}}|^3) $ (Kap. \ref{subsubsec:complex-max-al-lh}) und die Berechnung der wahrscheinlichsten Loci-Zuordnung in $O( l\, \cdotp n^3  \, \cdotp |V_{C_{i}}|^3 + n  \, \cdotp n!)$ (Kap. \ref{subsubsec:compl_loci_lh}). Die durchschnittliche Readlänge umfasst meist nur wenige hundert Basen, sie kann insbesondere bei großen Datensätzen als konstant betrachtet werden. Dadurch lässt sich die Gesamtlaufzeit von NodeRAD wie folgt zusammenfassen:
\begin{equation} \label{eqn:4-26}
\tag{4-26}
\begin{aligned}
&\ {}O(V \, \cdotp (V + E)) + O\left( \sum_{i=1}^{|C|} e^n\, \cdotp n\, \cdotp |V_{C_{i}}| + l\, \cdotp n^2\, \cdotp |V_{C_{i}}|^3) + l\, \cdotp n^3  \, \cdotp |V_{C_{i}}|^3 + n  \, \cdotp n! \right) \\
&\ \in O\left( V \, \cdotp (V + E) + \sum_{i=1}^{|C|} e^n\, \cdotp n\, \cdotp |V_{C_{i}}| + l\, \cdotp n^3  \, \cdotp |V_{C_{i}}|^3 + n  \, \cdotp n! \right) \\
&\ \stackrel{l = const.}{=} O\left( V \, \cdotp (V + E) + \sum_{i=1}^{|C|} e^n\, \cdotp n\, \cdotp |V_{C_{i}}| + n^3  \, \cdotp |V_{C_{i}}|^3 + n  \, \cdotp n! \right) \\
&\ = O\left( V \, \cdotp (V + E) + \sum_{i=1}^{|C|} e^n\, \cdotp n\, \cdotp |V_{C_{i}}| + \sum_{i=1}^{|C|} n^3  \, \cdotp |V_{C_{i}}|^3 + \sum_{i=1}^{|C|} n  \, \cdotp n! \right) \\
&\ \in O\left(\sum_{i=1}^{|C|} e^n\, \cdotp n\, \cdotp |V_{C_{i}}| + \sum_{i=1}^{|C|} n  \, \cdotp n! \right) \\
&\ \in O\left(\sum_{i=1}^{|C|} n  \, \cdotp n! \right) \\
\end{aligned}
\end{equation}

Würden im Worst Case alle Reads in allen Zusammenhangskomponenten aufgrund unterschiedlicher Sequenzen als Kandidatenallele gewertet werden, also $n = |V_{C_{i}}|$ für alle Komponenten $C_{i}$, dann ergäbe sich nach Formel \eqref{eqn:4-27} eine Laufzeit von $O(|V|!)$. 

\begin{equation} \label{eqn:4-27}
\tag{4-27}
\begin{aligned}
&\ {} O\left(\sum_{i=1}^{|C|} n  \, \cdotp n! \right) = O\left(\sum_{i=1}^{|C|} |V_{C_{i}}|  \, \cdotp |V_{C_{i}}|! \right) \\
&\ = O(|V|  \, \cdotp |V|!) \in O(|V|!)\\
\end{aligned}
\end{equation}

Ein solches Szenario ist jedoch sehr unwahrscheinlich. In allen übrigen Fällen wird die Laufzeit durch die Anzahl der Kandidatenallele der einzelnen Komponenten bestimmt, so dass die Optimierung der Schwellenwerte von zentraler Bedeutung für das Laufzeitverhalten ist. Zudem ist $n$ meistens sehr klein und hängt in der Regel nicht von der Anzahl der Reads ab. Vielmehr hängt es von der Repetitivität des Genoms und von der Ploidie ab.
\let\cleardoublepage\clearpage